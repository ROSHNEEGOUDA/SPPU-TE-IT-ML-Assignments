{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0aa8a5-4068-446d-8012-f6df3d6d805d",
   "metadata": {},
   "source": [
    "5. Assignment on Association Rule Learning\n",
    "Download Market Basket Optimization dataset from below link.\n",
    "Data Set: https://www.kaggle.com/hemanthkumar05/market-basket-optimization\n",
    "This dataset comprises the list of transactions of a retail company over the period of one week.\n",
    "It contains a total of 7501 transaction records where each record consists of the list of items\n",
    "sold in one transaction. Using this record of transactions and items in each transaction, find the\n",
    "association rules between items.\n",
    "There is no header in the dataset and the first row contains the first transaction, so mentioned\n",
    "header = None here while loading dataset.\n",
    "A. Follow following steps :\n",
    "B. Data Preprocessing\n",
    "C. Generate the list of transactions from the dataset\n",
    "D. Train Apriori algorithm on the dataset\n",
    "E. Visualize the list of rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cbe370cf-3db9-41ee-9d2c-355203334b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras-visualizer in c:\\users\\smile\\anaconda3\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\smile\\anaconda3\\lib\\site-packages (from keras-visualizer) (0.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras-visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5223532a-b31b-45eb-802c-a99b855cfcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd\n",
    "from keras_visualizer import visualizer\n",
    "from keras import models, layers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebff6e95-323c-4011-be42-8c9fc300d08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>116</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.6</td>\n",
       "      <td>0.201</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>10</td>\n",
       "      <td>101</td>\n",
       "      <td>76</td>\n",
       "      <td>48</td>\n",
       "      <td>180</td>\n",
       "      <td>32.9</td>\n",
       "      <td>0.171</td>\n",
       "      <td>63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>70</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>36.8</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>72</td>\n",
       "      <td>23</td>\n",
       "      <td>112</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.245</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>1</td>\n",
       "      <td>126</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.1</td>\n",
       "      <td>0.349</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>1</td>\n",
       "      <td>93</td>\n",
       "      <td>70</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.315</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>767 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      6  148  72  35    0  33.6  0.627  50  1\n",
       "0     1   85  66  29    0  26.6  0.351  31  0\n",
       "1     8  183  64   0    0  23.3  0.672  32  1\n",
       "2     1   89  66  23   94  28.1  0.167  21  0\n",
       "3     0  137  40  35  168  43.1  2.288  33  1\n",
       "4     5  116  74   0    0  25.6  0.201  30  0\n",
       "..   ..  ...  ..  ..  ...   ...    ...  .. ..\n",
       "762  10  101  76  48  180  32.9  0.171  63  0\n",
       "763   2  122  70  27    0  36.8  0.340  27  0\n",
       "764   5  121  72  23  112  26.2  0.245  30  0\n",
       "765   1  126  60   0    0  30.1  0.349  47  1\n",
       "766   1   93  70  31    0  30.4  0.315  23  0\n",
       "\n",
       "[767 rows x 9 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f7ff91-14b7-458d-9637-ad5620087652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 767 entries, 0 to 766\n",
      "Data columns (total 9 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   6       767 non-null    int64  \n",
      " 1   148     767 non-null    int64  \n",
      " 2   72      767 non-null    int64  \n",
      " 3   35      767 non-null    int64  \n",
      " 4   0       767 non-null    int64  \n",
      " 5   33.6    767 non-null    float64\n",
      " 6   0.627   767 non-null    float64\n",
      " 7   50      767 non-null    int64  \n",
      " 8   1       767 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f441bfb5-effa-4f6a-8714-d9b7614efc20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>6</th>\n",
       "      <th>148</th>\n",
       "      <th>72</th>\n",
       "      <th>35</th>\n",
       "      <th>0</th>\n",
       "      <th>33.6</th>\n",
       "      <th>0.627</th>\n",
       "      <th>50</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "      <td>767.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.842243</td>\n",
       "      <td>120.859192</td>\n",
       "      <td>69.101695</td>\n",
       "      <td>20.517601</td>\n",
       "      <td>79.903520</td>\n",
       "      <td>31.990482</td>\n",
       "      <td>0.471674</td>\n",
       "      <td>33.219035</td>\n",
       "      <td>0.348110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.370877</td>\n",
       "      <td>31.978468</td>\n",
       "      <td>19.368155</td>\n",
       "      <td>15.954059</td>\n",
       "      <td>115.283105</td>\n",
       "      <td>7.889091</td>\n",
       "      <td>0.331497</td>\n",
       "      <td>11.752296</td>\n",
       "      <td>0.476682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.500000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                6         148          72          35           0        33.6  \\\n",
       "count  767.000000  767.000000  767.000000  767.000000  767.000000  767.000000   \n",
       "mean     3.842243  120.859192   69.101695   20.517601   79.903520   31.990482   \n",
       "std      3.370877   31.978468   19.368155   15.954059  115.283105    7.889091   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      1.000000   99.000000   62.000000    0.000000    0.000000   27.300000   \n",
       "50%      3.000000  117.000000   72.000000   23.000000   32.000000   32.000000   \n",
       "75%      6.000000  140.000000   80.000000   32.000000  127.500000   36.600000   \n",
       "max     17.000000  199.000000  122.000000   99.000000  846.000000   67.100000   \n",
       "\n",
       "            0.627          50           1  \n",
       "count  767.000000  767.000000  767.000000  \n",
       "mean     0.471674   33.219035    0.348110  \n",
       "std      0.331497   11.752296    0.476682  \n",
       "min      0.078000   21.000000    0.000000  \n",
       "25%      0.243500   24.000000    0.000000  \n",
       "50%      0.371000   29.000000    0.000000  \n",
       "75%      0.625000   41.000000    1.000000  \n",
       "max      2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dcf3563d-3c5a-4872-81e7-51d781900e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5051 - loss: 0.7012 - val_accuracy: 0.6429 - val_loss: 0.6963\n",
      "Epoch 2/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6387 - loss: 0.6390 - val_accuracy: 0.6299 - val_loss: 0.6561\n",
      "Epoch 3/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6858 - loss: 0.6028 - val_accuracy: 0.6753 - val_loss: 0.6231\n",
      "Epoch 4/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7225 - loss: 0.5793 - val_accuracy: 0.7013 - val_loss: 0.6012\n",
      "Epoch 5/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7498 - loss: 0.5279 - val_accuracy: 0.7338 - val_loss: 0.5849\n",
      "Epoch 6/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7237 - loss: 0.5254 - val_accuracy: 0.7403 - val_loss: 0.5718\n",
      "Epoch 7/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 0.4900 - val_accuracy: 0.7403 - val_loss: 0.5625\n",
      "Epoch 8/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7287 - loss: 0.5241 - val_accuracy: 0.7468 - val_loss: 0.5546\n",
      "Epoch 9/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7471 - loss: 0.4860 - val_accuracy: 0.7273 - val_loss: 0.5476\n",
      "Epoch 10/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7862 - loss: 0.4614 - val_accuracy: 0.7403 - val_loss: 0.5410\n",
      "Epoch 11/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8040 - loss: 0.4666 - val_accuracy: 0.7338 - val_loss: 0.5384\n",
      "Epoch 12/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7617 - loss: 0.4577 - val_accuracy: 0.7468 - val_loss: 0.5317\n",
      "Epoch 13/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7739 - loss: 0.4700 - val_accuracy: 0.7338 - val_loss: 0.5278\n",
      "Epoch 14/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7743 - loss: 0.4644 - val_accuracy: 0.7273 - val_loss: 0.5269\n",
      "Epoch 15/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7818 - loss: 0.4397 - val_accuracy: 0.7338 - val_loss: 0.5227\n",
      "Epoch 16/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7508 - loss: 0.4863 - val_accuracy: 0.7338 - val_loss: 0.5209\n",
      "Epoch 17/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7652 - loss: 0.4744 - val_accuracy: 0.7468 - val_loss: 0.5188\n",
      "Epoch 18/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7859 - loss: 0.4353 - val_accuracy: 0.7468 - val_loss: 0.5169\n",
      "Epoch 19/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7777 - loss: 0.4459 - val_accuracy: 0.7532 - val_loss: 0.5163\n",
      "Epoch 20/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7759 - loss: 0.4495 - val_accuracy: 0.7532 - val_loss: 0.5153\n",
      "Epoch 21/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7763 - loss: 0.4577 - val_accuracy: 0.7468 - val_loss: 0.5148\n",
      "Epoch 22/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7854 - loss: 0.4307 - val_accuracy: 0.7532 - val_loss: 0.5140\n",
      "Epoch 23/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7940 - loss: 0.4275 - val_accuracy: 0.7532 - val_loss: 0.5115\n",
      "Epoch 24/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7860 - loss: 0.4455 - val_accuracy: 0.7532 - val_loss: 0.5112\n",
      "Epoch 25/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7797 - loss: 0.4373 - val_accuracy: 0.7532 - val_loss: 0.5102\n",
      "Epoch 26/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7721 - loss: 0.4600 - val_accuracy: 0.7597 - val_loss: 0.5087\n",
      "Epoch 27/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8060 - loss: 0.4177 - val_accuracy: 0.7597 - val_loss: 0.5081\n",
      "Epoch 28/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7901 - loss: 0.4266 - val_accuracy: 0.7662 - val_loss: 0.5077\n",
      "Epoch 29/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7833 - loss: 0.4515 - val_accuracy: 0.7662 - val_loss: 0.5078\n",
      "Epoch 30/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7718 - loss: 0.4645 - val_accuracy: 0.7662 - val_loss: 0.5066\n",
      "Epoch 31/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7804 - loss: 0.4251 - val_accuracy: 0.7662 - val_loss: 0.5057\n",
      "Epoch 32/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8030 - loss: 0.4314 - val_accuracy: 0.7662 - val_loss: 0.5070\n",
      "Epoch 33/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7803 - loss: 0.4316 - val_accuracy: 0.7662 - val_loss: 0.5050\n",
      "Epoch 34/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8328 - loss: 0.3858 - val_accuracy: 0.7597 - val_loss: 0.5051\n",
      "Epoch 35/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7962 - loss: 0.4129 - val_accuracy: 0.7662 - val_loss: 0.5040\n",
      "Epoch 36/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7870 - loss: 0.4136 - val_accuracy: 0.7727 - val_loss: 0.5055\n",
      "Epoch 37/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8086 - loss: 0.4027 - val_accuracy: 0.7597 - val_loss: 0.5043\n",
      "Epoch 38/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8081 - loss: 0.4173 - val_accuracy: 0.7662 - val_loss: 0.5021\n",
      "Epoch 39/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7974 - loss: 0.4384 - val_accuracy: 0.7662 - val_loss: 0.5031\n",
      "Epoch 40/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8139 - loss: 0.4134 - val_accuracy: 0.7662 - val_loss: 0.5040\n",
      "Epoch 41/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7944 - loss: 0.4349 - val_accuracy: 0.7597 - val_loss: 0.5023\n",
      "Epoch 42/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7831 - loss: 0.4382 - val_accuracy: 0.7662 - val_loss: 0.5032\n",
      "Epoch 43/100\n",
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7948 - loss: 0.4019 - val_accuracy: 0.7597 - val_loss: 0.5037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x27a44f70d40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example columns: ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', \n",
    "# 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome']\n",
    "# Split data into features and labels\n",
    "X = df.iloc[:, :-1].values  # Features (all columns except the last one)\n",
    "y = df.iloc[:, -1].values   # Labels (last column)\n",
    "\n",
    "# Scale features for better model performance\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X.shape[1], activation='relu'))  # Number of input features = X.shape[1]\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # Sigmoid for binary classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ec8d3374-f498-455c-9203-17cddda5f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizer(model, file_format='png', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "146c76d7-0a43-4063-90ba-03c562ee459c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 79.93%\n",
      "Training Error: 20.07%\n",
      "Testing Accuracy: 76.62%\n",
      "Testing Error: 23.38%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the training set\n",
    "_, train_accuracy = model.evaluate(X_train, y_train, verbose=0)  # Set verbose=0 to suppress output\n",
    "train_error = 1 - train_accuracy\n",
    "\n",
    "# Evaluate the model on the validation/testing set\n",
    "_, test_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "test_error = 1 - test_accuracy\n",
    "\n",
    "# Print the results\n",
    "print(f'Training Accuracy: {train_accuracy * 100:.2f}%')\n",
    "print(f'Training Error: {train_error * 100:.2f}%')\n",
    "\n",
    "print(f'Testing Accuracy: {test_accuracy * 100:.2f}%')\n",
    "print(f'Testing Error: {test_error * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5637a44a-324d-4287-86bb-58eb5f319003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the following details:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Number of pregnancies:  5\n",
      "Glucose level:  6\n",
      "Blood pressure:  4\n",
      "Skin thickness:  5\n",
      "Insulin level:  7\n",
      "BMI:  8\n",
      "Diabetes Pedigree Function:  9\n",
      "Age:  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "The model predicts that you are not diabetic.\n"
     ]
    }
   ],
   "source": [
    "# Function to get user input\n",
    "def get_user_input():\n",
    "    print(\"Please enter the following details:\")\n",
    "    pregnancies = float(input(\"Number of pregnancies: \"))\n",
    "    glucose = float(input(\"Glucose level: \"))\n",
    "    blood_pressure = float(input(\"Blood pressure: \"))\n",
    "    skin_thickness = float(input(\"Skin thickness: \"))\n",
    "    insulin = float(input(\"Insulin level: \"))\n",
    "    bmi = float(input(\"BMI: \"))\n",
    "    diabetes_pedigree = float(input(\"Diabetes Pedigree Function: \"))\n",
    "    age = float(input(\"Age: \"))\n",
    "    \n",
    "    # Store inputs in a NumPy array and scale it using the same scaler used for training\n",
    "    user_data = np.array([[pregnancies, glucose, blood_pressure, skin_thickness, \n",
    "                           insulin, bmi, diabetes_pedigree, age]])\n",
    "    user_data = scaler.transform(user_data)  # Scale the input\n",
    "    return user_data\n",
    "\n",
    "# Predict whether the user is diabetic or not\n",
    "def predict_diabetes():\n",
    "    user_data = get_user_input()\n",
    "    prediction = model.predict(user_data)\n",
    "    \n",
    "    # Sigmoid output gives a probability, so we threshold at 0.5\n",
    "    if prediction >= 0.5:\n",
    "        print(\"The model predicts that you are diabetic.\")\n",
    "    else:\n",
    "        print(\"The model predicts that you are not diabetic.\")\n",
    "\n",
    "# Call the prediction function\n",
    "predict_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb710269-a45d-4874-9f4f-682062490986",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
